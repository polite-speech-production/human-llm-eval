# human-llm-eval
the repo for running human-LLM response evaluation
